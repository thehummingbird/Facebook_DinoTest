{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DinoTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtYoU6+aFVs1sfjepAHx9W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thehummingbird/Facebook_DinoTest/blob/main/DinoTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycb_endYZLdO",
        "outputId": "4f34861d-6c8d-4ee7-8910-15043c74a293"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "#root_path = 'gdrive/My Drive/Colab Notebooks/'  #change dir to your project folder\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00eb90K5ZcQ_"
      },
      "source": [
        "import os\n",
        "os.chdir('gdrive/My Drive/') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkEzuZl5ZqwR",
        "outputId": "dc59d740-6e31-454e-c908-461f58c9a6b9"
      },
      "source": [
        "!mkdir dinoTest\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITbcL6HSZrX8"
      },
      "source": [
        "os.chdir('DinoTest/') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWWV4QBlZwcq"
      },
      "source": [
        "!mkdir input\n",
        "!mkdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf4qZ2SqZ56_",
        "outputId": "98ba7bac-0166-498d-8f09-930193ea1999"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/dino.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 113\u001b[K\n",
            "Receiving objects: 100% (113/113), 24.42 MiB | 24.00 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39g4eay8aA2Z",
        "outputId": "26db69e7-35b2-41f9-cab7-c828b1aa8949"
      },
      "source": [
        "\n",
        "!wget https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth -O dino/dino_deitsmall8_pretrain.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-04 09:51:39--  https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86728949 (83M) [application/zip]\n",
            "Saving to: ‘dino/dino_deitsmall8_pretrain.pth’\n",
            "\n",
            "dino/dino_deitsmall 100%[===================>]  82.71M  52.1MB/s    in 1.6s    \n",
            "\n",
            "2021-06-04 09:51:41 (52.1 MB/s) - ‘dino/dino_deitsmall8_pretrain.pth’ saved [86728949/86728949]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68DNlcL_aGVa",
        "outputId": "dee01617-ed52-45ac-86c4-d3557fb6e556"
      },
      "source": [
        "!ffmpeg -i dog.mp4 input/img-%03d.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'dog.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42mp41\n",
            "    creation_time   : 2021-06-04T09:29:22.000000Z\n",
            "  Duration: 00:00:21.35, start: 0.000000, bitrate: 5318 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 5001 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-06-04T09:29:22.000000Z\n",
            "      handler_name    : ?Mainconcept Video Media Handler\n",
            "      encoder         : AVC Coding\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 317 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-06-04T09:29:22.000000Z\n",
            "      handler_name    : #Mainconcept MP4 Sound Media Handler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x55578ba20000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to 'input/img-%03d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-06-04T09:29:22.000000Z\n",
            "      handler_name    : ?Mainconcept Video Media Handler\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  638 fps= 59 q=24.8 Lsize=N/A time=00:00:21.28 bitrate=N/A speed=1.97x    \n",
            "video:10161kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4rOTIX4a5uD",
        "outputId": "a1de21e2-a3d4-44f2-eb1f-e96c2cda3314"
      },
      "source": [
        "%cd dino"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DinoTest/dino\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhJJLLiEbHRP"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import skimage.io\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import utils\n",
        "import vision_transformer as vits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNruedTXbJfO"
      },
      "source": [
        "def predict_video(args):\n",
        "    for frame in sorted(os.listdir(args.image_path)):\n",
        "        with open(os.path.join(args.image_path, frame), 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        transform = pth_transforms.Compose([\n",
        "            pth_transforms.ToTensor(),\n",
        "            pth_transforms.Resize(512),\n",
        "            pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "        img = transform(img)\n",
        "\n",
        "        # make the image divisible by the patch size\n",
        "        w, h = img.shape[1] - img.shape[1] % args.patch_size, img.shape[2] - img.shape[2] % args.patch_size\n",
        "        img = img[:, :w, :h].unsqueeze(0)\n",
        "\n",
        "        w_featmap = img.shape[-2] // args.patch_size\n",
        "        h_featmap = img.shape[-1] // args.patch_size\n",
        "\n",
        "        attentions = model.forward_selfattention(img.cuda())\n",
        "\n",
        "        nh = attentions.shape[1] # number of head\n",
        "\n",
        "        # we keep only the output patch attention\n",
        "        attentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n",
        "\n",
        "        # we keep only a certain percentage of the mass\n",
        "        val, idx = torch.sort(attentions)\n",
        "        val /= torch.sum(val, dim=1, keepdim=True)\n",
        "        cumval = torch.cumsum(val, dim=1)\n",
        "        th_attn = cumval > (1 - args.threshold)\n",
        "        idx2 = torch.argsort(idx)\n",
        "        for head in range(nh):\n",
        "            th_attn[head] = th_attn[head][idx2[head]]\n",
        "        th_attn = th_attn.reshape(nh, w_featmap, h_featmap).float()\n",
        "        # interpolate\n",
        "        th_attn = nn.functional.interpolate(th_attn.unsqueeze(0), scale_factor=args.patch_size, mode=\"nearest\")[0].cpu().numpy()\n",
        "\n",
        "        attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
        "        attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=args.patch_size, mode=\"nearest\")[0].cpu().numpy()\n",
        "\n",
        "        # save attentions heatmaps\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "        # Saving only last attention layer\n",
        "        fname = os.path.join(args.output_dir, \"attn-\" + frame)\n",
        "        plt.imsave(\n",
        "            fname=fname,\n",
        "            arr=sum(attentions[i] * 1/attentions.shape[0] for i in range(attentions.shape[0])),\n",
        "            cmap=\"inferno\",\n",
        "            format=\"jpg\"\n",
        "        )\n",
        "        print(f\"{fname} saved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms91H57Bb0Q6"
      },
      "source": [
        "#@title Args\n",
        "\n",
        "pretrained_weights_path = \"dino_deitsmall8_pretrain.pth\" #@param {type:\"string\"}\n",
        "arch = 'deit_small' #@param [\"deit_small\", \"deit_tiny\", \"vit_base\"]\n",
        "input_path = \"../input/\" #@param {type:\"string\"}\n",
        "output_path = \"../output/\" #@param {type:\"string\"}\n",
        "threshold = 0.6 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser('Visualize Self-Attention maps')\n",
        "parser.add_argument('--arch', default='deit_small', type=str,\n",
        "    choices=['deit_tiny', 'deit_small', 'vit_base'], help='Architecture (support only ViT atm).')\n",
        "parser.add_argument('--patch_size', default=8, type=int, help='Patch resolution of the model.')\n",
        "parser.add_argument('--pretrained_weights', default='', type=str,\n",
        "    help=\"Path to pretrained weights to load.\")\n",
        "parser.add_argument(\"--checkpoint_key\", default=\"teacher\", type=str,\n",
        "    help='Key to use in the checkpoint (example: \"teacher\")')\n",
        "parser.add_argument(\"--image_path\", default=None, type=str, help=\"Path of the image to load.\")\n",
        "parser.add_argument('--output_dir', default='.', help='Path where to save visualizations.')\n",
        "parser.add_argument(\"--threshold\", type=float, default=0.6, help=\"\"\"We visualize masks\n",
        "    obtained by thresholding the self-attention maps to keep xx% of the mass.\"\"\")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "args.arch = arch\n",
        "args.pretrained_weights = pretrained_weights_path\n",
        "args.image_path = input_path\n",
        "args.output_dir = output_path\n",
        "args.threshold = threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7bmJrDqb2ov",
        "outputId": "ef0a49c9-e7d9-4b66-e781-0c2ab60f4729"
      },
      "source": [
        "model = vits.__dict__[args.arch](patch_size=args.patch_size, num_classes=0)\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "model.eval()\n",
        "model.cuda()\n",
        "if os.path.isfile(args.pretrained_weights):\n",
        "    state_dict = torch.load(args.pretrained_weights, map_location=\"cpu\")\n",
        "    if args.checkpoint_key is not None and args.checkpoint_key in state_dict:\n",
        "        print(f\"Take key {args.checkpoint_key} in provided checkpoint dict\")\n",
        "        state_dict = state_dict[args.checkpoint_key]\n",
        "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "    msg = model.load_state_dict(state_dict, strict=False)\n",
        "    print('Pretrained weights found at {} and loaded with msg: {}'.format(args.pretrained_weights, msg))\n",
        "else:\n",
        "    print(\"Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\")\n",
        "    url = None\n",
        "    if args.arch == \"deit_small\" and args.patch_size == 16:\n",
        "        url = \"dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\"\n",
        "    elif args.arch == \"deit_small\" and args.patch_size == 8:\n",
        "        url = \"dino_deitsmall8_300ep_pretrain/dino_deitsmall8_300ep_pretrain.pth\"  # model used for visualizations in our paper\n",
        "    elif args.arch == \"vit_base\" and args.patch_size == 16:\n",
        "        url = \"dino_vitbase16_pretrain/dino_vitbase16_pretrain.pth\"\n",
        "    elif args.arch == \"vit_base\" and args.patch_size == 8:\n",
        "        url = \"dino_vitbase8_pretrain/dino_vitbase8_pretrain.pth\"\n",
        "    if url is not None:\n",
        "        print(\"Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\")\n",
        "        state_dict = torch.hub.load_state_dict_from_url(url=\"https://dl.fbaipublicfiles.com/dino/\" + url)\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "    else:\n",
        "        print(\"There is no reference weights available for this model => We use random weights.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretrained weights found at dino_deitsmall8_pretrain.pth and loaded with msg: <All keys matched successfully>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80FXG0-Db-Rr",
        "outputId": "16d2372e-7085-4d21-9fde-687e6dff2764"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZrJTh9vOca2U",
        "outputId": "e6b56bac-d0a6-4dd4-91b6-a9daa876c54b"
      },
      "source": [
        "predict_video(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3503: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "../output/attn-img-001.jpg saved.\n",
            "../output/attn-img-002.jpg saved.\n",
            "../output/attn-img-003.jpg saved.\n",
            "../output/attn-img-004.jpg saved.\n",
            "../output/attn-img-005.jpg saved.\n",
            "../output/attn-img-006.jpg saved.\n",
            "../output/attn-img-007.jpg saved.\n",
            "../output/attn-img-008.jpg saved.\n",
            "../output/attn-img-009.jpg saved.\n",
            "../output/attn-img-010.jpg saved.\n",
            "../output/attn-img-011.jpg saved.\n",
            "../output/attn-img-012.jpg saved.\n",
            "../output/attn-img-013.jpg saved.\n",
            "../output/attn-img-014.jpg saved.\n",
            "../output/attn-img-015.jpg saved.\n",
            "../output/attn-img-016.jpg saved.\n",
            "../output/attn-img-017.jpg saved.\n",
            "../output/attn-img-018.jpg saved.\n",
            "../output/attn-img-019.jpg saved.\n",
            "../output/attn-img-020.jpg saved.\n",
            "../output/attn-img-021.jpg saved.\n",
            "../output/attn-img-022.jpg saved.\n",
            "../output/attn-img-023.jpg saved.\n",
            "../output/attn-img-024.jpg saved.\n",
            "../output/attn-img-025.jpg saved.\n",
            "../output/attn-img-026.jpg saved.\n",
            "../output/attn-img-027.jpg saved.\n",
            "../output/attn-img-028.jpg saved.\n",
            "../output/attn-img-029.jpg saved.\n",
            "../output/attn-img-030.jpg saved.\n",
            "../output/attn-img-031.jpg saved.\n",
            "../output/attn-img-032.jpg saved.\n",
            "../output/attn-img-033.jpg saved.\n",
            "../output/attn-img-034.jpg saved.\n",
            "../output/attn-img-035.jpg saved.\n",
            "../output/attn-img-036.jpg saved.\n",
            "../output/attn-img-037.jpg saved.\n",
            "../output/attn-img-038.jpg saved.\n",
            "../output/attn-img-039.jpg saved.\n",
            "../output/attn-img-040.jpg saved.\n",
            "../output/attn-img-041.jpg saved.\n",
            "../output/attn-img-042.jpg saved.\n",
            "../output/attn-img-043.jpg saved.\n",
            "../output/attn-img-044.jpg saved.\n",
            "../output/attn-img-045.jpg saved.\n",
            "../output/attn-img-046.jpg saved.\n",
            "../output/attn-img-047.jpg saved.\n",
            "../output/attn-img-048.jpg saved.\n",
            "../output/attn-img-049.jpg saved.\n",
            "../output/attn-img-050.jpg saved.\n",
            "../output/attn-img-051.jpg saved.\n",
            "../output/attn-img-052.jpg saved.\n",
            "../output/attn-img-053.jpg saved.\n",
            "../output/attn-img-054.jpg saved.\n",
            "../output/attn-img-055.jpg saved.\n",
            "../output/attn-img-056.jpg saved.\n",
            "../output/attn-img-057.jpg saved.\n",
            "../output/attn-img-058.jpg saved.\n",
            "../output/attn-img-059.jpg saved.\n",
            "../output/attn-img-060.jpg saved.\n",
            "../output/attn-img-061.jpg saved.\n",
            "../output/attn-img-062.jpg saved.\n",
            "../output/attn-img-063.jpg saved.\n",
            "../output/attn-img-064.jpg saved.\n",
            "../output/attn-img-065.jpg saved.\n",
            "../output/attn-img-066.jpg saved.\n",
            "../output/attn-img-067.jpg saved.\n",
            "../output/attn-img-068.jpg saved.\n",
            "../output/attn-img-069.jpg saved.\n",
            "../output/attn-img-070.jpg saved.\n",
            "../output/attn-img-071.jpg saved.\n",
            "../output/attn-img-072.jpg saved.\n",
            "../output/attn-img-073.jpg saved.\n",
            "../output/attn-img-074.jpg saved.\n",
            "../output/attn-img-075.jpg saved.\n",
            "../output/attn-img-076.jpg saved.\n",
            "../output/attn-img-077.jpg saved.\n",
            "../output/attn-img-078.jpg saved.\n",
            "../output/attn-img-079.jpg saved.\n",
            "../output/attn-img-080.jpg saved.\n",
            "../output/attn-img-081.jpg saved.\n",
            "../output/attn-img-082.jpg saved.\n",
            "../output/attn-img-083.jpg saved.\n",
            "../output/attn-img-084.jpg saved.\n",
            "../output/attn-img-085.jpg saved.\n",
            "../output/attn-img-086.jpg saved.\n",
            "../output/attn-img-087.jpg saved.\n",
            "../output/attn-img-088.jpg saved.\n",
            "../output/attn-img-089.jpg saved.\n",
            "../output/attn-img-090.jpg saved.\n",
            "../output/attn-img-091.jpg saved.\n",
            "../output/attn-img-092.jpg saved.\n",
            "../output/attn-img-093.jpg saved.\n",
            "../output/attn-img-094.jpg saved.\n",
            "../output/attn-img-095.jpg saved.\n",
            "../output/attn-img-096.jpg saved.\n",
            "../output/attn-img-097.jpg saved.\n",
            "../output/attn-img-098.jpg saved.\n",
            "../output/attn-img-099.jpg saved.\n",
            "../output/attn-img-100.jpg saved.\n",
            "../output/attn-img-101.jpg saved.\n",
            "../output/attn-img-102.jpg saved.\n",
            "../output/attn-img-103.jpg saved.\n",
            "../output/attn-img-104.jpg saved.\n",
            "../output/attn-img-105.jpg saved.\n",
            "../output/attn-img-106.jpg saved.\n",
            "../output/attn-img-107.jpg saved.\n",
            "../output/attn-img-108.jpg saved.\n",
            "../output/attn-img-109.jpg saved.\n",
            "../output/attn-img-110.jpg saved.\n",
            "../output/attn-img-111.jpg saved.\n",
            "../output/attn-img-112.jpg saved.\n",
            "../output/attn-img-113.jpg saved.\n",
            "../output/attn-img-114.jpg saved.\n",
            "../output/attn-img-115.jpg saved.\n",
            "../output/attn-img-116.jpg saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-60e00ae57b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-1af6ff335ad4>\u001b[0m in \u001b[0;36mpredict_video\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# we keep only a certain percentage of the mass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcumval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS1xN9UUrDi1",
        "outputId": "471997dc-f8b8-44b1-b791-6977e5709fec"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dino_deitsmall8_pretrain.pth  LICENSE\t\t    video_generation.py\n",
            "eval_knn.py\t\t      main_dino.py\t    vision_transformer.py\n",
            "eval_linear.py\t\t      README.md\t\t    visualize_attention.py\n",
            "eval_video_segmentation.py    run_with_submitit.py\n",
            "hubconf.py\t\t      utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v9tKsG5eWXS",
        "outputId": "4656d3b2-3f45-4c18-998a-0dcd07bf19e0"
      },
      "source": [
        "!ffmpeg -pattern_type glob -i '../output/*.jpg' -vcodec libx264 ../out.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '../output/*.jpg':\n",
            "  Duration: 00:00:04.64, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 904x512 [SAR 100:100 DAR 113:64], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mprofile High, level 3.1\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '../out.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 904x512 [SAR 100:100 DAR 113:64], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  116 fps= 80 q=-1.0 Lsize=     204kB time=00:00:04.52 bitrate= 370.0kbits/s speed=3.12x    \n",
            "video:202kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.082252%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mframe I:1     Avg QP:15.40  size:  3244\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mframe P:30    Avg QP:18.36  size:  4044\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mframe B:85    Avg QP:19.29  size:   959\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mconsecutive B-frames:  0.9%  3.4%  2.6% 93.1%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mmb I  I16..4: 46.4% 53.5%  0.1%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mmb P  I16..4: 10.0% 19.9%  0.3%  P16..4:  9.0%  2.6%  2.2%  0.0%  0.0%    skip:56.0%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mmb B  I16..4:  0.9%  2.0%  0.1%  B16..8: 13.6%  1.6%  0.2%  direct: 2.1%  skip:79.5%  L0:55.0% L1:43.9% BI: 1.1%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0m8x8 transform intra:65.4% inter:99.2%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mcoded y,uvDC,uvAC intra: 17.6% 52.4% 21.5% inter: 1.8% 6.0% 1.3%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mi16 v,h,dc,p: 38% 46% 15%  1%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 16% 60%  1%  0%  0%  0%  0%  4%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 59% 34%  6%  0%  0%  0%  0%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mi8c dc,h,v,p: 51% 30% 16%  4%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mWeighted P-Frames: Y:50.0% UV:50.0%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mref P L0: 48.2%  5.9% 21.3% 16.2%  8.4%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mref B L0: 81.8% 14.8%  3.4%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mref B L1: 92.8%  7.2%\n",
            "\u001b[1;36m[libx264 @ 0x56351cbd7e00] \u001b[0mkb/s:355.35\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}